from __future__ import annotations

import argparse
import json
from dataclasses import dataclass
from pathlib import Path

import numpy as np
from rlchef.env import EnvConfig, default_env


@dataclass(frozen=True)
class AggRow:
    algo: str
    state_mode: str
    n: int
    return_mean: float
    return_std: float
    steps_mean: float
    steps_std: float
    waste_mean: float
    waste_std: float
    incompat_mean: float
    incompat_std: float
    auc_mean: float
    auc_std: float
    last_mean: float
    last_std: float


def _mean_std(x: list[float]) -> tuple[float, float]:
    if not x:
        return 0.0, 0.0
    a = np.asarray(x, dtype=np.float64)
    return float(a.mean()), float(a.std(ddof=0))


def _fmt(mu: float, sigma: float, *, digits: int = 3) -> str:
    return f"{mu:.{digits}f} $\\pm$ {sigma:.{digits}f}"


def _key_from_run_id(run_id: str) -> tuple[str, str] | None:
    # keys look like: "{algo}-{state_mode}-seed{seed}"
    parts = run_id.split("-")
    if len(parts) < 3:
        return None
    algo = parts[0]
    state_mode = parts[1]
    return algo, state_mode


def write_table(rows: list[AggRow], outfile: Path) -> None:
    rows = sorted(rows, key=lambda r: (r.algo, r.state_mode))
    lines: list[str] = []
    lines.append("% Auto-generated by: python -m rlchef.analyze")
    lines.append("\\begin{tabular}{llrcccc}")
    lines.append("\\toprule")
    lines.append("Algo & State & $n$ & Return (eval) & Steps (eval) & Waste & Incompat \\\\")
    lines.append("\\midrule")
    for r in rows:
        lines.append(
            f"{r.algo} & {r.state_mode} & {r.n} & "
            f"{_fmt(r.return_mean, r.return_std)} & "
            f"{_fmt(r.steps_mean, r.steps_std, digits=2)} & "
            f"{_fmt(r.waste_mean, r.waste_std, digits=2)} & "
            f"{_fmt(r.incompat_mean, r.incompat_std, digits=2)} \\\\"
        )
    lines.append("\\bottomrule")
    lines.append("\\end{tabular}")
    outfile.write_text("\n".join(lines) + "\n", encoding="utf-8")


def _moving_average(x: np.ndarray, window: int) -> np.ndarray:
    w = int(window)
    if w <= 1:
        return x
    if x.size < w:
        # fallback: constant line at the mean
        return np.full_like(x, float(np.mean(x)) if x.size > 0 else 0.0)
    kernel = np.ones(w, dtype=np.float64) / float(w)
    return np.convolve(x, kernel, mode="valid")


def _cfg_label(algo: str, state_mode: str) -> str:
    return f"{algo}-{state_mode}"


def _sort_cfgs(cfgs: list[tuple[str, str]]) -> list[tuple[str, str]]:
    order_algo = {"qlearning": 0, "sarsa": 1, "linear": 2}
    order_state = {"simple": 0, "mask": 1}
    return sorted(cfgs, key=lambda t: (order_algo.get(t[0], 99), order_state.get(t[1], 99), t[0], t[1]))


def plot_eval_return_boxplot(summaries: list[dict], out_png: Path, *, dpi: int = 200) -> None:
    from matplotlib import pyplot as plt  # type: ignore

    groups: dict[tuple[str, str], list[float]] = {}
    for r in summaries:
        k = (str(r["algo"]), str(r["state_mode"]))
        groups.setdefault(k, []).append(float(r["return_mean"]))

    cfgs = _sort_cfgs(list(groups.keys()))
    data = [groups[c] for c in cfgs]
    labels = [_cfg_label(*c) for c in cfgs]

    plt.figure(figsize=(10, 4))
    # Matplotlib renamed "labels" -> "tick_labels" in 3.9 (remove warning on newer versions).
    try:
        plt.boxplot(data, tick_labels=labels, showmeans=True)  # type: ignore[call-arg]
    except TypeError:
        plt.boxplot(data, labels=labels, showmeans=True)
    plt.xticks(rotation=20, ha="right")
    plt.ylabel("eval return (mean over eval episodes)")
    plt.title("Evaluation return distribution across seeds")
    plt.grid(True, axis="y", alpha=0.25)
    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close()


def plot_steps_bars(summaries: list[dict], out_png: Path, *, dpi: int = 200) -> None:
    from matplotlib import pyplot as plt  # type: ignore

    groups: dict[tuple[str, str], list[float]] = {}
    for r in summaries:
        k = (str(r["algo"]), str(r["state_mode"]))
        groups.setdefault(k, []).append(float(r["steps_mean"]))

    cfgs = _sort_cfgs(list(groups.keys()))
    mu = [float(np.mean(groups[c])) for c in cfgs]
    sd = [float(np.std(groups[c], ddof=0)) for c in cfgs]
    labels = [_cfg_label(*c) for c in cfgs]

    plt.figure(figsize=(10, 4))
    x = np.arange(len(cfgs))
    plt.bar(x, mu, yerr=sd, capsize=4)
    plt.xticks(x, labels, rotation=20, ha="right")
    plt.ylabel("steps (eval)")
    plt.title("Policy efficiency: episode length (mean ± std across seeds)")
    plt.grid(True, axis="y", alpha=0.25)
    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close()


def plot_waste_incompat_bars(summaries: list[dict], out_png: Path, *, dpi: int = 200) -> None:
    from matplotlib import pyplot as plt  # type: ignore

    groups_w: dict[tuple[str, str], list[float]] = {}
    groups_i: dict[tuple[str, str], list[float]] = {}
    for r in summaries:
        k = (str(r["algo"]), str(r["state_mode"]))
        groups_w.setdefault(k, []).append(float(r["waste_mean"]))
        groups_i.setdefault(k, []).append(float(r["incompat_mean"]))

    cfgs = _sort_cfgs(list(groups_w.keys()))
    labels = [_cfg_label(*c) for c in cfgs]
    w_mu = [float(np.mean(groups_w[c])) for c in cfgs]
    w_sd = [float(np.std(groups_w[c], ddof=0)) for c in cfgs]
    i_mu = [float(np.mean(groups_i[c])) for c in cfgs]
    i_sd = [float(np.std(groups_i[c], ddof=0)) for c in cfgs]

    x = np.arange(len(cfgs))
    width = 0.42
    plt.figure(figsize=(10, 4))
    plt.bar(x - width / 2, w_mu, width, yerr=w_sd, capsize=4, label="waste")
    plt.bar(x + width / 2, i_mu, width, yerr=i_sd, capsize=4, label="incompat")
    plt.xticks(x, labels, rotation=20, ha="right")
    plt.ylabel("mean penalty components (eval)")
    plt.title("Interpretability: waste vs incompatibility (mean ± std across seeds)")
    plt.grid(True, axis="y", alpha=0.25)
    plt.legend()
    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close()


def plot_tradeoff_scatter(summaries: list[dict], out_png: Path, *, dpi: int = 200) -> None:
    from matplotlib import pyplot as plt  # type: ignore

    plt.figure(figsize=(10, 4))
    colors = {("qlearning", "simple"): "#e74c3c", ("qlearning", "mask"): "#2ecc71", ("linear", "simple"): "#3498db", ("linear", "mask"): "#9b59b6"}
    for r in summaries:
        algo = str(r["algo"])
        state = str(r["state_mode"])
        key = (algo, state)
        c = colors.get(key, "#7f8c8d")
        x = float(r["waste_mean"]) + float(r["incompat_mean"])
        y = float(r["return_mean"])
        plt.scatter(x, y, color=c, alpha=0.7, s=28, edgecolors="none")
    plt.xlabel("waste + incompat (eval)")
    plt.ylabel("eval return")
    plt.title("Trade-off across seeds: return vs penalties")
    plt.grid(True, alpha=0.25)
    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close()


def plot_made_distribution(summaries: list[dict], out_png: Path, *, dpi: int = 200, top_k: int = 6) -> None:
    from matplotlib import pyplot as plt  # type: ignore

    # Aggregate counts across seeds per config
    by_cfg: dict[tuple[str, str], dict[str, int]] = {}
    all_recipes: dict[str, int] = {}
    for r in summaries:
        cfg = (str(r["algo"]), str(r["state_mode"]))
        mc = dict(r.get("made_counts", {}))
        g = by_cfg.setdefault(cfg, {})
        for k, v in mc.items():
            name = "fail" if (k is None or str(k) == "None") else str(k)
            cnt = int(v)
            g[name] = g.get(name, 0) + cnt
            all_recipes[name] = all_recipes.get(name, 0) + cnt

    if not by_cfg:
        return

    # Choose top recipes by total count (keep "fail" if present)
    items = sorted(all_recipes.items(), key=lambda kv: kv[1], reverse=True)
    keep = [name for name, _ in items if name != "fail"][: max(1, int(top_k) - 1)]
    if "fail" in all_recipes:
        keep = ["fail"] + keep

    cfgs = _sort_cfgs(list(by_cfg.keys()))
    labels = [_cfg_label(*c) for c in cfgs]
    x = np.arange(len(cfgs))

    # Normalize to proportions
    mat = []
    for cfg in cfgs:
        d = by_cfg[cfg]
        total = float(sum(d.values())) if d else 1.0
        mat.append([float(d.get(name, 0)) / total for name in keep])
    mat = np.asarray(mat, dtype=np.float64)  # shape: [cfg, recipe]

    plt.figure(figsize=(11, 4))
    bottom = np.zeros(len(cfgs), dtype=np.float64)
    palette = ["#34495e", "#e74c3c", "#f1c40f", "#2ecc71", "#3498db", "#9b59b6", "#95a5a6"]
    for j, name in enumerate(keep):
        plt.bar(x, mat[:, j], bottom=bottom, label=name, color=palette[j % len(palette)])
        bottom += mat[:, j]
    plt.xticks(x, labels, rotation=20, ha="right")
    plt.ylabel("proportion of evaluated episodes")
    plt.title("Which dishes are produced? (stacked proportions; fail = no feasible recipe)")
    plt.grid(True, axis="y", alpha=0.25)
    plt.legend(ncol=3, fontsize=8)
    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close()


def plot_sample_efficiency(rows: list[AggRow], out_png: Path, *, dpi: int = 200) -> None:
    from matplotlib import pyplot as plt  # type: ignore

    rows_s = sorted(rows, key=lambda r: (r.algo, r.state_mode))
    labels = [f"{r.algo}-{r.state_mode}" for r in rows_s]
    x = np.arange(len(rows_s))

    auc = np.array([r.auc_mean for r in rows_s], dtype=np.float64)
    auc_sd = np.array([r.auc_std for r in rows_s], dtype=np.float64)
    last = np.array([r.last_mean for r in rows_s], dtype=np.float64)
    last_sd = np.array([r.last_std for r in rows_s], dtype=np.float64)

    width = 0.42
    plt.figure(figsize=(11, 4))
    plt.bar(x - width / 2, auc, width, yerr=auc_sd, capsize=4, label="train_return_auc")
    plt.bar(x + width / 2, last, width, yerr=last_sd, capsize=4, label="train_return_last_mean")
    plt.xticks(x, labels, rotation=20, ha="right")
    plt.ylabel("train return proxies")
    plt.title("Sample-efficiency / stability proxies from training curves (mean ± std across seeds)")
    plt.grid(True, axis="y", alpha=0.25)
    plt.legend()
    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close()


def write_env_specs(outfile: Path) -> None:
    """
    Write a LaTeX snippet with environment parameters and recipe definitions.
    Saved as a standalone tabular that can be \\input{}-ed from the paper.
    """
    env = default_env(seed=0, config=EnvConfig())
    cfg = env.cfg

    # Environment parameters (keep it concise and paper-friendly).
    lines: list[str] = []
    lines.append("% Auto-generated by: python -m rlchef.analyze --extra-figs")
    lines.append("\\begin{tabular}{ll}")
    lines.append("\\toprule")
    lines.append("Parameter & Value \\\\")
    lines.append("\\midrule")
    lines.append(f"Grid size & {cfg.size}$\\times${cfg.size} \\\\")
    lines.append(f"Actions & 5 (up, down, left, right, cook) \\\\")
    lines.append(f"Max steps & {cfg.max_steps} \\\\")
    lines.append(f"Pickup reward & {cfg.pickup_reward:.2f} \\\\")
    lines.append(f"Move penalty & {cfg.move_penalty:.2f} \\\\")
    lines.append(f"Waste penalty & {cfg.waste_penalty:.2f} per wasted item \\\\")
    lines.append(f"Incompatibility penalty & {cfg.incompat_penalty:.2f} per incompatible pair \\\\")
    lines.append(f"Fail penalty (no feasible recipe) & {cfg.fail_penalty:.2f} \\\\")
    lines.append(f"Extra penalty (cook with empty inv.) & {cfg.empty_cook_extra_penalty:.2f} \\\\")
    lines.append("\\midrule")
    lines.append("\\multicolumn{2}{l}{\\textbf{Recipes (value; required ingredients)}}\\\\")
    for rec in env.recipes:
        need = ", ".join(str(int(x)) for x in rec.need)
        lines.append(f"{rec.name} & {rec.value:.1f} ; ({need}) \\\\")
    lines.append("\\bottomrule")
    lines.append("\\end{tabular}")

    outfile.write_text("\n".join(lines) + "\n", encoding="utf-8")


def plot_env_layout(out_png: Path, *, dpi: int = 200) -> None:
    """
    Render a static overview of the fixed ingredient layout used in the experiments.
    This is intentionally matplotlib-based (no pygame) so it works on Overleaf/CI setups.
    """
    from matplotlib import pyplot as plt  # type: ignore

    env = default_env(seed=0, config=EnvConfig())
    obs, info = env.reset(seed=0)
    grid = info["grid"]
    names = env.ingredient_names
    s = int(env.cfg.size)

    plt.figure(figsize=(6.2, 5.2))
    plt.imshow(grid, cmap="tab20", interpolation="nearest")
    plt.xticks(range(s))
    plt.yticks(range(s))
    plt.title("RL Chef environment (fixed grid layout)")

    # Annotate each cell with ingredient id (and a short name).
    for i in range(s):
        for j in range(s):
            ing = int(grid[i, j])
            short = names[ing][:2]
            plt.text(j, i, f"{ing}\n{short}", ha="center", va="center", fontsize=9, color="black")

    # Add a small legend mapping id -> ingredient name.
    legend_lines = [f"{i}: {n}" for i, n in enumerate(names)]
    plt.gcf().text(0.02, 0.02, "Ingredients:\n" + "\n".join(legend_lines), fontsize=9)

    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close()

def plot_aggregate(
    curves_all: dict[str, dict[str, list[float]]],
    out_png: Path,
    *,
    smooth_window: int = 200,
    downsample: int = 10,
    dpi: int = 200,
) -> None:
    from matplotlib import pyplot as plt  # type: ignore

    # collect per-config curves
    by_cfg: dict[tuple[str, str], list[np.ndarray]] = {}
    ep_ref: np.ndarray | None = None
    for run_id, c in curves_all.items():
        k = _key_from_run_id(run_id)
        if k is None:
            continue
        ep = np.asarray(c["ep"], dtype=np.float64)
        ret = np.asarray(c["return_train"], dtype=np.float64)
        if ep_ref is None:
            ep_ref = ep
        # If episodes differ across runs, align by truncation to the shortest.
        n = int(min(ep_ref.size, ep.size, ret.size))
        ep_ref = ep_ref[:n]
        ret = ret[:n]
        by_cfg.setdefault(k, []).append(ret)

    if ep_ref is None or not by_cfg:
        return

    def agg(cfg: tuple[str, str]) -> tuple[np.ndarray, np.ndarray] | None:
        runs = by_cfg.get(cfg, [])
        if not runs:
            return None
        m = np.stack(runs, axis=0)
        return m.mean(axis=0), m.std(axis=0, ddof=0)

    # Smooth (moving average) and optional downsample for readability.
    sw = int(max(1, smooth_window))
    ds = int(max(1, downsample))
    ep_s = _moving_average(ep_ref, sw)

    def smooth_pair(mu: np.ndarray, sd: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
        mu_s = _moving_average(mu, sw)
        sd_s = _moving_average(sd, sw)
        return mu_s, sd_s

    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)
    panels = [
        ("qlearning", axes[0], "Tabular Q-learning"),
        ("linear", axes[1], "Linear function approximation"),
    ]
    for algo, ax, title in panels:
        ax.set_title(title)
        ax.set_xlabel("episode")
        ax.grid(True, alpha=0.25)

        # For linear, simple/mask are expected to be identical (state_mode affects only tabular state keys).
        if algo == "linear":
            res_s = agg((algo, "simple"))
            res_m = agg((algo, "mask"))
            if res_s is not None:
                mu, sd = smooth_pair(*res_s)
                ep = ep_s
                if ds > 1:
                    ep = ep[::ds]
                    mu = mu[::ds]
                    sd = sd[::ds]
                label = "simple/mask (identical)"
                ax.plot(ep, mu, label=label, color="#2ecc71", linewidth=2)
                ax.fill_between(ep, mu - sd, mu + sd, color="#2ecc71", alpha=0.18, linewidth=0)
            elif res_m is not None:
                mu, sd = smooth_pair(*res_m)
                ep = ep_s
                if ds > 1:
                    ep = ep[::ds]
                    mu = mu[::ds]
                    sd = sd[::ds]
                label = "simple/mask (identical)"
                ax.plot(ep, mu, label=label, color="#2ecc71", linewidth=2)
                ax.fill_between(ep, mu - sd, mu + sd, color="#2ecc71", alpha=0.18, linewidth=0)
        else:
            for state_mode, color in [("simple", "#e74c3c"), ("mask", "#2ecc71")]:
                res = agg((algo, state_mode))
                if res is None:
                    continue
                mu, sd = smooth_pair(*res)
                ep = ep_s
                if ds > 1:
                    ep = ep[::ds]
                    mu = mu[::ds]
                    sd = sd[::ds]
                ax.plot(ep, mu, label=f"{state_mode}", color=color, linewidth=2)
                ax.fill_between(ep, mu - sd, mu + sd, color=color, alpha=0.18, linewidth=0)

        ax.legend()
    axes[0].set_ylabel("train return")
    plt.tight_layout()
    plt.savefig(out_png, dpi=int(dpi))
    plt.close(fig)


def main() -> None:
    p = argparse.ArgumentParser()
    p.add_argument("--indir", type=str, default="results/rlchef", help="Directory containing summaries.json and curves.json")
    p.add_argument("--outdir", type=str, default=None, help="Where to write analysis outputs (defaults to --indir)")
    p.add_argument("--smooth-window", type=int, default=200, help="Moving-average window (episodes) for plots")
    p.add_argument("--downsample", type=int, default=10, help="Plot every N points after smoothing (for readability)")
    p.add_argument("--dpi", type=int, default=200, help="PNG DPI for saved plots")
    p.add_argument("--extra-figs", action="store_true", help="Generate additional paper figures from summaries.json")
    args = p.parse_args()

    indir = Path(args.indir)
    outdir = Path(args.outdir) if args.outdir is not None else indir
    outdir.mkdir(parents=True, exist_ok=True)

    summaries_path = indir / "summaries.json"
    curves_path = indir / "curves.json"
    if not summaries_path.exists():
        raise FileNotFoundError(f"Missing {summaries_path}. Run: python -m rlchef.experiments --outdir {indir}")
    if not curves_path.exists():
        raise FileNotFoundError(f"Missing {curves_path}. Run: python -m rlchef.experiments --outdir {indir}")

    summaries = json.loads(summaries_path.read_text(encoding="utf-8"))
    curves_all = json.loads(curves_path.read_text(encoding="utf-8"))

    grouped: dict[tuple[str, str], dict[str, list[float]]] = {}
    for r in summaries:
        key = (str(r["algo"]), str(r["state_mode"]))
        g = grouped.setdefault(
            key,
            {
                "return_mean": [],
                "steps_mean": [],
                "waste_mean": [],
                "incompat_mean": [],
                "train_return_auc": [],
                "train_return_last_mean": [],
            },
        )
        g["return_mean"].append(float(r["return_mean"]))
        g["steps_mean"].append(float(r["steps_mean"]))
        g["waste_mean"].append(float(r["waste_mean"]))
        g["incompat_mean"].append(float(r["incompat_mean"]))
        g["train_return_auc"].append(float(r["train_return_auc"]))
        g["train_return_last_mean"].append(float(r["train_return_last_mean"]))

    rows: list[AggRow] = []
    for (algo, state_mode), g in grouped.items():
        rm, rs = _mean_std(g["return_mean"])
        sm, ss = _mean_std(g["steps_mean"])
        wm, ws = _mean_std(g["waste_mean"])
        im, ins = _mean_std(g["incompat_mean"])
        am, astd = _mean_std(g["train_return_auc"])
        lm, lstd = _mean_std(g["train_return_last_mean"])
        n = len(g["return_mean"])
        rows.append(
            AggRow(
                algo=algo,
                state_mode=state_mode,
                n=n,
                return_mean=rm,
                return_std=rs,
                steps_mean=sm,
                steps_std=ss,
                waste_mean=wm,
                waste_std=ws,
                incompat_mean=im,
                incompat_std=ins,
                auc_mean=am,
                auc_std=astd,
                last_mean=lm,
                last_std=lstd,
            )
        )

    table_path = outdir / "metrics_table.tex"
    write_table(rows, table_path)
    plot_aggregate(
        curves_all,
        outdir / "returns_aggregate.png",
        smooth_window=int(args.smooth_window),
        downsample=int(args.downsample),
        dpi=int(args.dpi),
    )

    if bool(args.extra_figs):
        plot_eval_return_boxplot(summaries, outdir / "eval_return_boxplot.png", dpi=int(args.dpi))
        plot_steps_bars(summaries, outdir / "steps_bars.png", dpi=int(args.dpi))
        plot_waste_incompat_bars(summaries, outdir / "waste_incompat_bars.png", dpi=int(args.dpi))
        plot_tradeoff_scatter(summaries, outdir / "tradeoff_scatter.png", dpi=int(args.dpi))
        plot_made_distribution(summaries, outdir / "made_distribution.png", dpi=int(args.dpi))
        plot_sample_efficiency(rows, outdir / "sample_efficiency.png", dpi=int(args.dpi))
        plot_env_layout(outdir / "env_layout.png", dpi=int(args.dpi))
        write_env_specs(outdir / "env_specs.tex")

    # Also save a small JSON for convenience
    (outdir / "aggregate.json").write_text(
        json.dumps([r.__dict__ for r in rows], indent=2),
        encoding="utf-8",
    )
    print(f"Wrote: {table_path}")
    print(f"Wrote: {outdir / 'returns_aggregate.png'}")
    print(f"Wrote: {outdir / 'aggregate.json'}")


if __name__ == "__main__":
    main()

